{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import yake\n",
    "import gensim.downloader\n",
    "import gensim\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine = lambda a,b : np.dot(a,b)/(norm(a)*norm(b))\n",
    "euclidian = lambda a,b : norm(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(a,b):\n",
    "    d = np.dot(a,b)\n",
    "    na = norm(a)\n",
    "    nb = norm(b)\n",
    "    nanb = na*nb\n",
    "    return d / nanb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vect = gensim.downloader.load(\"fasttext-wiki-news-subwords-300\")\n",
    "\n",
    "vect = gensim.models.KeyedVectors.load_word2vec_format(r\"C:\\Users\\romaf\\gensim-data\\wiki-2017-gensim\\model.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwords = yake.KeywordExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/submission.csv',index_col=['#'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(data):\n",
    "    vectorised_data = []\n",
    "    for sentence in data:\n",
    "        sentence = sentence.replace(\"-\",\" \")\n",
    "        words = sentence.split()\n",
    "        sentence_vector = np.zeros([300])\n",
    "        for word in words:\n",
    "            try:\n",
    "                sentence_vector = sentence_vector + vect[word.lower()]\n",
    "            except Exception:\n",
    "                sentence_vector = None\n",
    "                break\n",
    "        vectorised_data.append(sentence_vector) \n",
    "    return vectorised_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum_vec(data):\n",
    "    sum_vec1 = np.zeros([300])\n",
    "    for vec in data:\n",
    "        if vec is not None:\n",
    "            sum_vec1 = sum_vec1 + vec\n",
    "    return sum_vec1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_sum_vec(data):\n",
    "    sum_vec1 = np.zeros([300])\n",
    "    for ind,vec in enumerate(data):\n",
    "        if vec is not None:\n",
    "            sum_vec1 = sum_vec1 + (vec * (1 - 0.01 * ind)) \n",
    "    return sum_vec1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vec_rpr(data):\n",
    "    title,keys,abstract = data\n",
    "\n",
    "    kw_from_abstract = [words for words,val in kwords.extract_keywords(abstract)]\n",
    "\n",
    "    kw_from_keys = [word for word in keys.split('\\n')]\n",
    "\n",
    "    vec_abstract = get_vectors(kw_from_abstract)\n",
    "\n",
    "    sum_vec_abstract = get_weight_sum_vec(vec_abstract)\n",
    "\n",
    "    vec_keys = get_vectors(kw_from_keys)\n",
    "\n",
    "    sum_vec_keys = get_weight_sum_vec(vec_keys)\n",
    "\n",
    "    return sum_vec_abstract,sum_vec_keys,sum_vec_abstract+sum_vec_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vec_rpr_kw_only(data):\n",
    "    keys = data\n",
    "\n",
    "    kw_from_keys = data\n",
    "\n",
    "    vec_keys = get_vectors(kw_from_keys)\n",
    "\n",
    "    sum_vec_keys = get_sum_vec(vec_keys)\n",
    "\n",
    "    return sum_vec_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[[\"title\",'keywords','abstract']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for ind,row in df2.iterrows():\n",
    "    data.append([row['title'],row['keywords'],row['abstract']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Autoencoding Language Model Based Ensemble Learning for Commonsense Validation and Explanation',\n",
       " 'Autoencoding Language Model\\nSiamese Neural Network\\nEnsemble Learning\\nCommonsense Validation\\nCommonsense Explanation',\n",
       " 'An ultimate goal of artificial intelligence is to build computer systems that can understand human languages. Understanding commonsense knowledge about the world expressed in text is one of the foundational and challenging problems to create such intelligent systems. As a step towards this goal, we present in this paper ALMEn, an Autoencoding Language Model based Ensemble learning method for commonsense validation and explanation. By ensembling several advanced pre-trained language models including RoBERTa, DeBERTa, and ELECTRA with Siamese neural networks, our method can distinguish\\r\\nnatural language statements that are against commonsense (validation subtask) and correctly identify the reason for making against commonsense (explanation selection subtask). Experimental results on the benchmark dataset of SemEval-2020 Task 4 show that our method outperforms state-of-the-art models, reaching 97.9% and 95.4% accuracies on the validation and explanation selection subtasks, respectively.']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab,kw,abkw = get_vec_rpr(data[1])\n",
    "a,k,ak = get_vec_rpr(data[64])\n",
    "ab = ab+a\n",
    "kw = kw +k\n",
    "abkw = abkw + ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 316/344 [00:41<00:04,  6.91it/s]C:\\Users\\romaf\\AppData\\Local\\Temp\\ipykernel_14296\\3083299470.py:1: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cosine = lambda a,b : np.dot(a,b)/(norm(a)*norm(b))\n",
      "100%|██████████| 344/344 [00:45<00:00,  7.52it/s]\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for data_val in tqdm(data):\n",
    "    title,keys,abstract = data_val\n",
    "    a,k,ak =get_vec_rpr(data_val)\n",
    "    res.append({\"title\":title,\"keys\":keys,\"abstract\":abstract,\"a\":cosine(ab,a),'k':cosine(kw,k),'ak':cosine(abkw,ak)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean_ak'] = ((df['a'] + df['k']) /2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>a</th>\n",
       "      <th>k</th>\n",
       "      <th>ak</th>\n",
       "      <th>mean_ak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XLMRQA: Open-Domain Question Answering on Vietnamese Wikipedia-based Textual Knowledge Source</td>\n",
       "      <td>0.982956</td>\n",
       "      <td>0.944438</td>\n",
       "      <td>0.983605</td>\n",
       "      <td>0.963697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Autoencoding Language Model Based Ensemble Learning for Commonsense Validation and Explanation</td>\n",
       "      <td>0.963838</td>\n",
       "      <td>0.892910</td>\n",
       "      <td>0.965764</td>\n",
       "      <td>0.928374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>OAK4XAI: Model towards Multi-Layer eXplainable Artificial Intelligence for Digital Agriculture</td>\n",
       "      <td>0.897037</td>\n",
       "      <td>0.725682</td>\n",
       "      <td>0.915372</td>\n",
       "      <td>0.811359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Error Investigation of Pre-trained BERTology Models on Vietnamese Natural Language Inference</td>\n",
       "      <td>0.879471</td>\n",
       "      <td>0.831736</td>\n",
       "      <td>0.891619</td>\n",
       "      <td>0.855603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Corpus based approach to semantic analysis Uzbek text</td>\n",
       "      <td>0.883444</td>\n",
       "      <td>0.756664</td>\n",
       "      <td>0.891000</td>\n",
       "      <td>0.820054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Improving Topic Quality with Interactive Beta-Liouville Mixture Allocation Model</td>\n",
       "      <td>0.860567</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>0.884422</td>\n",
       "      <td>0.832157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>End to End Neural Network for Tweet Text Prediction</td>\n",
       "      <td>0.884704</td>\n",
       "      <td>0.687556</td>\n",
       "      <td>0.876731</td>\n",
       "      <td>0.786130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Abstractive Text Summarization Utilising Pretrained Language Models</td>\n",
       "      <td>0.854707</td>\n",
       "      <td>0.743920</td>\n",
       "      <td>0.876663</td>\n",
       "      <td>0.799313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Speech Emotion Classification - A Survey of the State-of-the-Art</td>\n",
       "      <td>0.876870</td>\n",
       "      <td>0.699556</td>\n",
       "      <td>0.874467</td>\n",
       "      <td>0.788213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Performance Analysis of Digit Recognizer usingVarious Machine Learning Algorithms</td>\n",
       "      <td>0.861795</td>\n",
       "      <td>0.799101</td>\n",
       "      <td>0.874252</td>\n",
       "      <td>0.830448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Shapley Additive Explanations for Text Classification and Sentiment Analysis of Internet Movie Database</td>\n",
       "      <td>0.869228</td>\n",
       "      <td>0.714261</td>\n",
       "      <td>0.873398</td>\n",
       "      <td>0.791744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>A Deep Convolution Generative Adversarial Network for the Production of Images of Human Faces</td>\n",
       "      <td>0.872339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.871259</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Explainable Machine Learning for Sequences of Demographic Statuses</td>\n",
       "      <td>0.853706</td>\n",
       "      <td>0.758667</td>\n",
       "      <td>0.867938</td>\n",
       "      <td>0.806186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Layer-wise Optimization of Contextual Neural Networks with Dynamic Field of Aggregation</td>\n",
       "      <td>0.851803</td>\n",
       "      <td>0.612973</td>\n",
       "      <td>0.864838</td>\n",
       "      <td>0.732388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Semantic Pivoting Model for Effective Event Detection</td>\n",
       "      <td>0.853575</td>\n",
       "      <td>0.749093</td>\n",
       "      <td>0.863568</td>\n",
       "      <td>0.801334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>BERT-based Text Representation for Lifelong Learning on Indonesian Sentiment Analysis</td>\n",
       "      <td>0.842755</td>\n",
       "      <td>0.713487</td>\n",
       "      <td>0.860196</td>\n",
       "      <td>0.778121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Using Brain-Computer Interface (BCI) and Artificial Intelligence for EEG signal analysis</td>\n",
       "      <td>0.832719</td>\n",
       "      <td>0.750429</td>\n",
       "      <td>0.858807</td>\n",
       "      <td>0.791574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Using Brain-Computer Interface and Artificial Intelligence for EEG signal analysis</td>\n",
       "      <td>0.832719</td>\n",
       "      <td>0.750429</td>\n",
       "      <td>0.858807</td>\n",
       "      <td>0.791574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Digitization in Sports and Healthcare: Perspectives and Future Challenges</td>\n",
       "      <td>0.825169</td>\n",
       "      <td>0.637421</td>\n",
       "      <td>0.857504</td>\n",
       "      <td>0.731295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Context-free Transformer-based Generative Lemmatiser for Polish</td>\n",
       "      <td>0.839743</td>\n",
       "      <td>0.608395</td>\n",
       "      <td>0.856653</td>\n",
       "      <td>0.724069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Auto Machine Learning-Based Approach for Source Printer Identification</td>\n",
       "      <td>0.848003</td>\n",
       "      <td>0.731315</td>\n",
       "      <td>0.856418</td>\n",
       "      <td>0.789659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>Supervised learning use to acquire knowledge from 2D analytic geometry problems</td>\n",
       "      <td>0.825822</td>\n",
       "      <td>0.791037</td>\n",
       "      <td>0.856028</td>\n",
       "      <td>0.808429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>A Sustainable Approach to Marketable Banking Stress and Burnout</td>\n",
       "      <td>0.834726</td>\n",
       "      <td>0.794541</td>\n",
       "      <td>0.853999</td>\n",
       "      <td>0.814634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Complement Naive Bayes Classifier for Sentiment Analysis of Internet Movie Database</td>\n",
       "      <td>0.847091</td>\n",
       "      <td>0.571508</td>\n",
       "      <td>0.852604</td>\n",
       "      <td>0.709299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Syntactic and Cognitive Aspects of the VPE in Texts of School Planimetric Tasks</td>\n",
       "      <td>0.828134</td>\n",
       "      <td>0.769784</td>\n",
       "      <td>0.851406</td>\n",
       "      <td>0.798959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>The task of synthesizing the Kazakh language based on machine learning</td>\n",
       "      <td>0.846542</td>\n",
       "      <td>0.748583</td>\n",
       "      <td>0.850466</td>\n",
       "      <td>0.797563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>A Semantic-based Approach for Keyphrase Extraction from Vietnamese Documents</td>\n",
       "      <td>0.848089</td>\n",
       "      <td>0.580846</td>\n",
       "      <td>0.849682</td>\n",
       "      <td>0.714468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Analysis of dynamics of emergence and decline of scientic ideas based on optimistic and pessimistic fuzzy aggregation norms</td>\n",
       "      <td>0.791402</td>\n",
       "      <td>0.737531</td>\n",
       "      <td>0.849035</td>\n",
       "      <td>0.764467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>CORDIS Partner Matching Algorithm for Recommender Systems</td>\n",
       "      <td>0.782790</td>\n",
       "      <td>0.818324</td>\n",
       "      <td>0.844948</td>\n",
       "      <td>0.800557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Development of CRF and CTC based end-to-end Kazakh speech recognition system</td>\n",
       "      <td>0.819013</td>\n",
       "      <td>0.704753</td>\n",
       "      <td>0.843608</td>\n",
       "      <td>0.761883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Machine learning or lexicon based sentiment analysis techniques on social media posts</td>\n",
       "      <td>0.818093</td>\n",
       "      <td>0.797458</td>\n",
       "      <td>0.843114</td>\n",
       "      <td>0.807776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Keyword Extraction from Short Texts with a Text-To-Text Transfer Transformer</td>\n",
       "      <td>0.841427</td>\n",
       "      <td>0.532868</td>\n",
       "      <td>0.843059</td>\n",
       "      <td>0.687148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>A comparative study of classification and clustering methods from text of books</td>\n",
       "      <td>0.783661</td>\n",
       "      <td>0.819455</td>\n",
       "      <td>0.842717</td>\n",
       "      <td>0.801558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Federated Learning for Non-IID Data via Client Variance Reduction and Adaptive Server Update</td>\n",
       "      <td>0.837774</td>\n",
       "      <td>0.723748</td>\n",
       "      <td>0.842181</td>\n",
       "      <td>0.780761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Fairness of Machine Learning Algorithms in Demography</td>\n",
       "      <td>0.814008</td>\n",
       "      <td>0.777015</td>\n",
       "      <td>0.841949</td>\n",
       "      <td>0.795511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Triaging medical referrals based on Clinical Prioritisation Criteria using Cosine Similarity</td>\n",
       "      <td>0.831853</td>\n",
       "      <td>0.417357</td>\n",
       "      <td>0.841902</td>\n",
       "      <td>0.624605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>BeCaked+: An Explainable AI Model to Forecast Delta-spreading Covid-19 Situations for Ho Chi Minh City</td>\n",
       "      <td>0.835519</td>\n",
       "      <td>0.675537</td>\n",
       "      <td>0.841661</td>\n",
       "      <td>0.755528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Fuzzy Neural Machine Translation: A Preliminary Study</td>\n",
       "      <td>0.841446</td>\n",
       "      <td>0.718761</td>\n",
       "      <td>0.841210</td>\n",
       "      <td>0.780104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Using deep learning to detect anomalies in traffic flow</td>\n",
       "      <td>0.784110</td>\n",
       "      <td>0.737749</td>\n",
       "      <td>0.841023</td>\n",
       "      <td>0.760929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>LDA+: An Extended LDA Model for Topic Hierarchy and Discovery</td>\n",
       "      <td>0.822350</td>\n",
       "      <td>0.690653</td>\n",
       "      <td>0.840404</td>\n",
       "      <td>0.756501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Exploring Retriever-Reader Approaches in Question-Answering on Scientific Documents</td>\n",
       "      <td>0.831308</td>\n",
       "      <td>0.719904</td>\n",
       "      <td>0.840167</td>\n",
       "      <td>0.775606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Efficient Classification with Counterfactual Reasoning and Active Learning</td>\n",
       "      <td>0.822192</td>\n",
       "      <td>0.782129</td>\n",
       "      <td>0.839214</td>\n",
       "      <td>0.802160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Exploring the effect of vehicle appearance and motion for natural language-based vehicle retrieval</td>\n",
       "      <td>0.812810</td>\n",
       "      <td>0.695274</td>\n",
       "      <td>0.838467</td>\n",
       "      <td>0.754042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Russian Sign Language Dactyl Recognition</td>\n",
       "      <td>0.810586</td>\n",
       "      <td>0.735835</td>\n",
       "      <td>0.838315</td>\n",
       "      <td>0.773210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>ETop3PPE: Epoch’s Top-Three Prediction Probability Ensemble Method for Deep Learning Classification Models</td>\n",
       "      <td>0.837300</td>\n",
       "      <td>0.616817</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.727059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuzzy Based Motivation Assessment Model for Intelligent Tutoring System</td>\n",
       "      <td>0.812907</td>\n",
       "      <td>0.809927</td>\n",
       "      <td>0.833760</td>\n",
       "      <td>0.811417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Self-Optimizing Neural Network in classification of real valued experimental data</td>\n",
       "      <td>0.828835</td>\n",
       "      <td>0.630921</td>\n",
       "      <td>0.833420</td>\n",
       "      <td>0.729878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Trivi: A Customer Intelligence System for SMEs</td>\n",
       "      <td>0.846686</td>\n",
       "      <td>0.616679</td>\n",
       "      <td>0.833393</td>\n",
       "      <td>0.731682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>An Empirical experiment on Feature Extractions Based for Speech Emotion Recognition</td>\n",
       "      <td>0.829199</td>\n",
       "      <td>0.630945</td>\n",
       "      <td>0.832113</td>\n",
       "      <td>0.730072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>On Verified Automated Reasoning in Propositional Logic</td>\n",
       "      <td>0.811389</td>\n",
       "      <td>0.765886</td>\n",
       "      <td>0.831524</td>\n",
       "      <td>0.788637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Factors influencing perceived learning of students during online classes: A case study from Taiwan</td>\n",
       "      <td>0.818496</td>\n",
       "      <td>0.735707</td>\n",
       "      <td>0.831346</td>\n",
       "      <td>0.777101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>The problem of detecting boxers in the boxing ring</td>\n",
       "      <td>0.815610</td>\n",
       "      <td>0.671300</td>\n",
       "      <td>0.831096</td>\n",
       "      <td>0.743455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>FEBR: Expert-Based Recommendation Framework for beneficial and personalized content</td>\n",
       "      <td>0.814343</td>\n",
       "      <td>0.745472</td>\n",
       "      <td>0.830079</td>\n",
       "      <td>0.779907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>A Novel Integrating Approach Between Graph Neural Network and Complex Representation for Link Prediction in Knowledge Graph</td>\n",
       "      <td>0.830288</td>\n",
       "      <td>0.668462</td>\n",
       "      <td>0.829817</td>\n",
       "      <td>0.749375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Embedding Model with Attention over Convolution Kernels and Dynamic Mapping Matrix for Link Prediction</td>\n",
       "      <td>0.834297</td>\n",
       "      <td>0.688205</td>\n",
       "      <td>0.828698</td>\n",
       "      <td>0.761251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Personalized Hybrid Recommendation Based on Knowledge Graph</td>\n",
       "      <td>0.803800</td>\n",
       "      <td>0.748893</td>\n",
       "      <td>0.828165</td>\n",
       "      <td>0.776346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Predicting Survival on Titanic by Applying Data Analytics and Machine Learning Techniques</td>\n",
       "      <td>0.827867</td>\n",
       "      <td>0.687471</td>\n",
       "      <td>0.827994</td>\n",
       "      <td>0.757669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>ITCareerBot: A Personalized Career Counseling Chatbot</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.715471</td>\n",
       "      <td>0.827419</td>\n",
       "      <td>0.762944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Kazakh-Uzbek Machine Translation on the Base of Complete Set of Endings Model</td>\n",
       "      <td>0.796923</td>\n",
       "      <td>0.723325</td>\n",
       "      <td>0.827103</td>\n",
       "      <td>0.760124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Verifying EFL Autonomous Learning by Digital Gaming: Definitions and Concepts</td>\n",
       "      <td>0.837993</td>\n",
       "      <td>0.594328</td>\n",
       "      <td>0.826478</td>\n",
       "      <td>0.716161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>A Deep Learning Approach for Arabic Text Detection in Traffic Panels</td>\n",
       "      <td>0.812850</td>\n",
       "      <td>0.694287</td>\n",
       "      <td>0.826249</td>\n",
       "      <td>0.753568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Using machine learning algorithms to explore listeners’ musical tastes</td>\n",
       "      <td>0.808109</td>\n",
       "      <td>0.742997</td>\n",
       "      <td>0.824743</td>\n",
       "      <td>0.775553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>A Novel Neural Network Training Method for Autonomous Driving Using Semi-Pseudo-Labels and 3D Data Augmentations</td>\n",
       "      <td>0.799457</td>\n",
       "      <td>0.769101</td>\n",
       "      <td>0.823965</td>\n",
       "      <td>0.784279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Multimedia application for analyzing and planning scientific collaboration</td>\n",
       "      <td>0.821442</td>\n",
       "      <td>0.682869</td>\n",
       "      <td>0.823242</td>\n",
       "      <td>0.752155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Human voice identification based on the detection of  fundamental harmonics</td>\n",
       "      <td>0.797805</td>\n",
       "      <td>0.757562</td>\n",
       "      <td>0.822025</td>\n",
       "      <td>0.777683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Knowledge Base Completion and Temporal Knowledge Base Completion:  Some Experimental Studies</td>\n",
       "      <td>0.794918</td>\n",
       "      <td>0.733736</td>\n",
       "      <td>0.820639</td>\n",
       "      <td>0.764327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Machine Learning  Methods for BIM Data</td>\n",
       "      <td>0.810546</td>\n",
       "      <td>0.683144</td>\n",
       "      <td>0.820332</td>\n",
       "      <td>0.746845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Attend2trend: Attention-Based LSTM Model for Detecting and Forecasting of Trending Topics</td>\n",
       "      <td>0.815323</td>\n",
       "      <td>0.729619</td>\n",
       "      <td>0.820224</td>\n",
       "      <td>0.772471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Research of searching for vulnerabilities in machine code</td>\n",
       "      <td>0.808198</td>\n",
       "      <td>0.689369</td>\n",
       "      <td>0.819856</td>\n",
       "      <td>0.748783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Employing Generative Adversarial Network in COVID-19 diagnosis</td>\n",
       "      <td>0.796840</td>\n",
       "      <td>0.700803</td>\n",
       "      <td>0.819484</td>\n",
       "      <td>0.748822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Non-Contextual vs Contextual Word Embeddings in Multiword Expressions Detection</td>\n",
       "      <td>0.774824</td>\n",
       "      <td>0.697354</td>\n",
       "      <td>0.819226</td>\n",
       "      <td>0.736089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>G-Fake: Tell me how it is shared and I shall tell you if it is fake</td>\n",
       "      <td>0.808235</td>\n",
       "      <td>0.604217</td>\n",
       "      <td>0.819165</td>\n",
       "      <td>0.706226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Excess-Mass and Mass-Volume quality measures susceptibility to intrusion detection system's data dimensionality</td>\n",
       "      <td>0.785668</td>\n",
       "      <td>0.793849</td>\n",
       "      <td>0.818970</td>\n",
       "      <td>0.789758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Extractive Text Summarization on Vietnamese Large Scale Dataset</td>\n",
       "      <td>0.799784</td>\n",
       "      <td>0.651070</td>\n",
       "      <td>0.818109</td>\n",
       "      <td>0.725427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>“eRReBIS” Business Intelligence Based Intelligent Recommender System for e-recruitment process</td>\n",
       "      <td>0.765958</td>\n",
       "      <td>0.818137</td>\n",
       "      <td>0.817898</td>\n",
       "      <td>0.792047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>AIRBIS-2: Neuromorphic-based Biomedical System for Pneumonia Detection in Chest X-ray Images</td>\n",
       "      <td>0.829182</td>\n",
       "      <td>0.612303</td>\n",
       "      <td>0.817749</td>\n",
       "      <td>0.720743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>Random Forest in Whitelist-based ATM Security</td>\n",
       "      <td>0.786635</td>\n",
       "      <td>0.719223</td>\n",
       "      <td>0.816748</td>\n",
       "      <td>0.752929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Enhencing Vietnamese Question Generation with Reinforcement Learning</td>\n",
       "      <td>0.814584</td>\n",
       "      <td>0.634550</td>\n",
       "      <td>0.816544</td>\n",
       "      <td>0.724567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Artificial Intelligence in Physical Education and Sport</td>\n",
       "      <td>0.781222</td>\n",
       "      <td>0.743856</td>\n",
       "      <td>0.815475</td>\n",
       "      <td>0.762539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>UML profile for IoT-based applications</td>\n",
       "      <td>0.805540</td>\n",
       "      <td>0.660810</td>\n",
       "      <td>0.814707</td>\n",
       "      <td>0.733175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Meta-learning and Personalization layer in Federated learning</td>\n",
       "      <td>0.800810</td>\n",
       "      <td>0.722890</td>\n",
       "      <td>0.814389</td>\n",
       "      <td>0.761850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Relearning ensemble selection based on new generated features</td>\n",
       "      <td>0.803267</td>\n",
       "      <td>0.642116</td>\n",
       "      <td>0.813567</td>\n",
       "      <td>0.722692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Exploration of Ear Biometrics using Deep Learning</td>\n",
       "      <td>0.803638</td>\n",
       "      <td>0.720243</td>\n",
       "      <td>0.813418</td>\n",
       "      <td>0.761941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Towards Descriptive Summarization: \\\\  An Internet Monitoring Use Case</td>\n",
       "      <td>0.799814</td>\n",
       "      <td>0.713105</td>\n",
       "      <td>0.811904</td>\n",
       "      <td>0.756460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>A Framework for Brain-Computer Interfaces Closed-loop Communication Systems</td>\n",
       "      <td>0.823480</td>\n",
       "      <td>0.670745</td>\n",
       "      <td>0.811510</td>\n",
       "      <td>0.747113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Parameter Distribution Ensemble Learning  for Sudden Concept Drift Detection</td>\n",
       "      <td>0.789718</td>\n",
       "      <td>0.750202</td>\n",
       "      <td>0.811355</td>\n",
       "      <td>0.769960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Semantic Relationship-based Image Retrieval using KD-Tree Structure</td>\n",
       "      <td>0.810331</td>\n",
       "      <td>0.673109</td>\n",
       "      <td>0.810251</td>\n",
       "      <td>0.741720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Embedding and Integrating Literals to the HypER Model for Link Prediction on Knowledge Graphs</td>\n",
       "      <td>0.798586</td>\n",
       "      <td>0.687061</td>\n",
       "      <td>0.809863</td>\n",
       "      <td>0.742824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Implementation of Chatbot on Mental Health Applications to Help Mobile-Based Mental Health</td>\n",
       "      <td>0.796993</td>\n",
       "      <td>0.694665</td>\n",
       "      <td>0.809393</td>\n",
       "      <td>0.745829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Optimizing the choice of information security means using a genetic algorithm</td>\n",
       "      <td>0.805585</td>\n",
       "      <td>0.702734</td>\n",
       "      <td>0.809328</td>\n",
       "      <td>0.754159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Fusing Deep Learning with Support Vector Machines to Detect COVID-19 in X-Ray</td>\n",
       "      <td>0.798575</td>\n",
       "      <td>0.754467</td>\n",
       "      <td>0.809055</td>\n",
       "      <td>0.776521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>FASENet: A Two-Stream Fall Detection and Activity Monitoring Model using Pose Keypoints and Squeeze-and-Excitation Networks</td>\n",
       "      <td>0.771506</td>\n",
       "      <td>0.718812</td>\n",
       "      <td>0.808981</td>\n",
       "      <td>0.745159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Multimedia Web application for analyzing and planning scientific collaboration</td>\n",
       "      <td>0.804909</td>\n",
       "      <td>0.682869</td>\n",
       "      <td>0.808450</td>\n",
       "      <td>0.743889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>A Homomorphic Encryption Approach for Privacy-Preserving Deep Learning in Digital Health Care Service</td>\n",
       "      <td>0.749709</td>\n",
       "      <td>0.714394</td>\n",
       "      <td>0.808349</td>\n",
       "      <td>0.732052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Music Emotion Recognition Based on Term Frequency and Pattern Entropy</td>\n",
       "      <td>0.789809</td>\n",
       "      <td>0.761703</td>\n",
       "      <td>0.808042</td>\n",
       "      <td>0.775756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Association Discovery from Electronic Medical Records towards Personalized Treatment</td>\n",
       "      <td>0.777191</td>\n",
       "      <td>0.716652</td>\n",
       "      <td>0.807397</td>\n",
       "      <td>0.746921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Neural Inverse Text Normalization with Numerical Recognition for Low Resource Scenarios</td>\n",
       "      <td>0.792451</td>\n",
       "      <td>0.753670</td>\n",
       "      <td>0.806658</td>\n",
       "      <td>0.773060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Semantic-based Image Retrieval using RS-Tree and Knowledge Graph</td>\n",
       "      <td>0.809374</td>\n",
       "      <td>0.584146</td>\n",
       "      <td>0.805850</td>\n",
       "      <td>0.696760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>FROM THE PORTAL TO THE LINGUISTIC PLATFORM “TURKIC MORPHEME”</td>\n",
       "      <td>0.818898</td>\n",
       "      <td>0.608742</td>\n",
       "      <td>0.805113</td>\n",
       "      <td>0.713820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>“TURKIC MORPHEME”: FROM THE PORTAL TO THE LINGUISTIC PLATFORM</td>\n",
       "      <td>0.818898</td>\n",
       "      <td>0.608742</td>\n",
       "      <td>0.805113</td>\n",
       "      <td>0.713820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                           title  \\\n",
       "1                                  XLMRQA: Open-Domain Question Answering on Vietnamese Wikipedia-based Textual Knowledge Source   \n",
       "64                                Autoencoding Language Model Based Ensemble Learning for Commonsense Validation and Explanation   \n",
       "317                               OAK4XAI: Model towards Multi-Layer eXplainable Artificial Intelligence for Digital Agriculture   \n",
       "311                                 Error Investigation of Pre-trained BERTology Models on Vietnamese Natural Language Inference   \n",
       "38                                                                         Corpus based approach to semantic analysis Uzbek text   \n",
       "253                                             Improving Topic Quality with Interactive Beta-Liouville Mixture Allocation Model   \n",
       "145                                                                          End to End Neural Network for Tweet Text Prediction   \n",
       "62                                                           Abstractive Text Summarization Utilising Pretrained Language Models   \n",
       "287                                                             Speech Emotion Classification - A Survey of the State-of-the-Art   \n",
       "165                                            Performance Analysis of Digit Recognizer usingVarious Machine Learning Algorithms   \n",
       "153                      Shapley Additive Explanations for Text Classification and Sentiment Analysis of Internet Movie Database   \n",
       "316                                A Deep Convolution Generative Adversarial Network for the Production of Images of Human Faces   \n",
       "32                                                            Explainable Machine Learning for Sequences of Demographic Statuses   \n",
       "338                                      Layer-wise Optimization of Contextual Neural Networks with Dynamic Field of Aggregation   \n",
       "119                                                                        Semantic Pivoting Model for Effective Event Detection   \n",
       "156                                        BERT-based Text Representation for Lifelong Learning on Indonesian Sentiment Analysis   \n",
       "169                                     Using Brain-Computer Interface (BCI) and Artificial Intelligence for EEG signal analysis   \n",
       "245                                           Using Brain-Computer Interface and Artificial Intelligence for EEG signal analysis   \n",
       "77                                                     Digitization in Sports and Healthcare: Perspectives and Future Challenges   \n",
       "151                                                              Context-free Transformer-based Generative Lemmatiser for Polish   \n",
       "208                                                       Auto Machine Learning-Based Approach for Source Printer Identification   \n",
       "266                                              Supervised learning use to acquire knowledge from 2D analytic geometry problems   \n",
       "225                                                              A Sustainable Approach to Marketable Banking Stress and Burnout   \n",
       "27                                           Complement Naive Bayes Classifier for Sentiment Analysis of Internet Movie Database   \n",
       "185                                             Syntactic and Cognitive Aspects of the VPE in Texts of School Planimetric Tasks    \n",
       "95                                                        The task of synthesizing the Kazakh language based on machine learning   \n",
       "154                                                 A Semantic-based Approach for Keyphrase Extraction from Vietnamese Documents   \n",
       "181  Analysis of dynamics of emergence and decline of scientic ideas based on optimistic and pessimistic fuzzy aggregation norms   \n",
       "330                                                                    CORDIS Partner Matching Algorithm for Recommender Systems   \n",
       "4                                                   Development of CRF and CTC based end-to-end Kazakh speech recognition system   \n",
       "40                                         Machine learning or lexicon based sentiment analysis techniques on social media posts   \n",
       "291                                                 Keyword Extraction from Short Texts with a Text-To-Text Transfer Transformer   \n",
       "54                                              A comparative study of classification and clustering methods from text of books    \n",
       "282                                 Federated Learning for Non-IID Data via Client Variance Reduction and Adaptive Server Update   \n",
       "182                                                                        Fairness of Machine Learning Algorithms in Demography   \n",
       "24                                  Triaging medical referrals based on Clinical Prioritisation Criteria using Cosine Similarity   \n",
       "52                        BeCaked+: An Explainable AI Model to Forecast Delta-spreading Covid-19 Situations for Ho Chi Minh City   \n",
       "298                                                                        Fuzzy Neural Machine Translation: A Preliminary Study   \n",
       "299                                                                      Using deep learning to detect anomalies in traffic flow   \n",
       "148                                                                LDA+: An Extended LDA Model for Topic Hierarchy and Discovery   \n",
       "251                                          Exploring Retriever-Reader Approaches in Question-Answering on Scientific Documents   \n",
       "173                                                   Efficient Classification with Counterfactual Reasoning and Active Learning   \n",
       "258                           Exploring the effect of vehicle appearance and motion for natural language-based vehicle retrieval   \n",
       "183                                                                                     Russian Sign Language Dactyl Recognition   \n",
       "215                   ETop3PPE: Epoch’s Top-Three Prediction Probability Ensemble Method for Deep Learning Classification Models   \n",
       "2                                                       Fuzzy Based Motivation Assessment Model for Intelligent Tutoring System    \n",
       "284                                            Self-Optimizing Neural Network in classification of real valued experimental data   \n",
       "170                                                                               Trivi: A Customer Intelligence System for SMEs   \n",
       "214                                          An Empirical experiment on Feature Extractions Based for Speech Emotion Recognition   \n",
       "72                                                                        On Verified Automated Reasoning in Propositional Logic   \n",
       "117                           Factors influencing perceived learning of students during online classes: A case study from Taiwan   \n",
       "31                                                                            The problem of detecting boxers in the boxing ring   \n",
       "65                                           FEBR: Expert-Based Recommendation Framework for beneficial and personalized content   \n",
       "137  A Novel Integrating Approach Between Graph Neural Network and Complex Representation for Link Prediction in Knowledge Graph   \n",
       "216                       Embedding Model with Attention over Convolution Kernels and Dynamic Mapping Matrix for Link Prediction   \n",
       "5                                                                    Personalized Hybrid Recommendation Based on Knowledge Graph   \n",
       "164                                    Predicting Survival on Titanic by Applying Data Analytics and Machine Learning Techniques   \n",
       "115                                                                        ITCareerBot: A Personalized Career Counseling Chatbot   \n",
       "135                                                Kazakh-Uzbek Machine Translation on the Base of Complete Set of Endings Model   \n",
       "283                                                Verifying EFL Autonomous Learning by Digital Gaming: Definitions and Concepts   \n",
       "108                                                         A Deep Learning Approach for Arabic Text Detection in Traffic Panels   \n",
       "328                                                       Using machine learning algorithms to explore listeners’ musical tastes   \n",
       "255             A Novel Neural Network Training Method for Autonomous Driving Using Semi-Pseudo-Labels and 3D Data Augmentations   \n",
       "175                                                   Multimedia application for analyzing and planning scientific collaboration   \n",
       "42                                                   Human voice identification based on the detection of  fundamental harmonics   \n",
       "286                                 Knowledge Base Completion and Temporal Knowledge Base Completion:  Some Experimental Studies   \n",
       "274                                                                                       Machine Learning  Methods for BIM Data   \n",
       "13                                     Attend2trend: Attention-Based LSTM Model for Detecting and Forecasting of Trending Topics   \n",
       "78                                                                     Research of searching for vulnerabilities in machine code   \n",
       "224                                                               Employing Generative Adversarial Network in COVID-19 diagnosis   \n",
       "140                                              Non-Contextual vs Contextual Word Embeddings in Multiword Expressions Detection   \n",
       "129                                                          G-Fake: Tell me how it is shared and I shall tell you if it is fake   \n",
       "73               Excess-Mass and Mass-Volume quality measures susceptibility to intrusion detection system's data dimensionality   \n",
       "30                                                               Extractive Text Summarization on Vietnamese Large Scale Dataset   \n",
       "55                                “eRReBIS” Business Intelligence Based Intelligent Recommender System for e-recruitment process   \n",
       "325                                 AIRBIS-2: Neuromorphic-based Biomedical System for Pneumonia Detection in Chest X-ray Images   \n",
       "334                                                                                Random Forest in Whitelist-based ATM Security   \n",
       "93                                                          Enhencing Vietnamese Question Generation with Reinforcement Learning   \n",
       "33                                                                       Artificial Intelligence in Physical Education and Sport   \n",
       "273                                                                                       UML profile for IoT-based applications   \n",
       "210                                                                Meta-learning and Personalization layer in Federated learning   \n",
       "313                                                                Relearning ensemble selection based on new generated features   \n",
       "264                                                                            Exploration of Ear Biometrics using Deep Learning   \n",
       "288                                                       Towards Descriptive Summarization: \\\\  An Internet Monitoring Use Case   \n",
       "250                                                  A Framework for Brain-Computer Interfaces Closed-loop Communication Systems   \n",
       "227                                                 Parameter Distribution Ensemble Learning  for Sudden Concept Drift Detection   \n",
       "226                                                          Semantic Relationship-based Image Retrieval using KD-Tree Structure   \n",
       "144                                Embedding and Integrating Literals to the HypER Model for Link Prediction on Knowledge Graphs   \n",
       "120                                   Implementation of Chatbot on Mental Health Applications to Help Mobile-Based Mental Health   \n",
       "9                                                  Optimizing the choice of information security means using a genetic algorithm   \n",
       "106                                                Fusing Deep Learning with Support Vector Machines to Detect COVID-19 in X-Ray   \n",
       "309  FASENet: A Two-Stream Fall Detection and Activity Monitoring Model using Pose Keypoints and Squeeze-and-Excitation Networks   \n",
       "213                                               Multimedia Web application for analyzing and planning scientific collaboration   \n",
       "104                        A Homomorphic Encryption Approach for Privacy-Preserving Deep Learning in Digital Health Care Service   \n",
       "10                                                         Music Emotion Recognition Based on Term Frequency and Pattern Entropy   \n",
       "308                                         Association Discovery from Electronic Medical Records towards Personalized Treatment   \n",
       "190                                      Neural Inverse Text Normalization with Numerical Recognition for Low Resource Scenarios   \n",
       "233                                                             Semantic-based Image Retrieval using RS-Tree and Knowledge Graph   \n",
       "123                                                                 FROM THE PORTAL TO THE LINGUISTIC PLATFORM “TURKIC MORPHEME”   \n",
       "222                                                                “TURKIC MORPHEME”: FROM THE PORTAL TO THE LINGUISTIC PLATFORM   \n",
       "\n",
       "            a         k        ak   mean_ak  \n",
       "1    0.982956  0.944438  0.983605  0.963697  \n",
       "64   0.963838  0.892910  0.965764  0.928374  \n",
       "317  0.897037  0.725682  0.915372  0.811359  \n",
       "311  0.879471  0.831736  0.891619  0.855603  \n",
       "38   0.883444  0.756664  0.891000  0.820054  \n",
       "253  0.860567  0.803747  0.884422  0.832157  \n",
       "145  0.884704  0.687556  0.876731  0.786130  \n",
       "62   0.854707  0.743920  0.876663  0.799313  \n",
       "287  0.876870  0.699556  0.874467  0.788213  \n",
       "165  0.861795  0.799101  0.874252  0.830448  \n",
       "153  0.869228  0.714261  0.873398  0.791744  \n",
       "316  0.872339       NaN  0.871259       NaN  \n",
       "32   0.853706  0.758667  0.867938  0.806186  \n",
       "338  0.851803  0.612973  0.864838  0.732388  \n",
       "119  0.853575  0.749093  0.863568  0.801334  \n",
       "156  0.842755  0.713487  0.860196  0.778121  \n",
       "169  0.832719  0.750429  0.858807  0.791574  \n",
       "245  0.832719  0.750429  0.858807  0.791574  \n",
       "77   0.825169  0.637421  0.857504  0.731295  \n",
       "151  0.839743  0.608395  0.856653  0.724069  \n",
       "208  0.848003  0.731315  0.856418  0.789659  \n",
       "266  0.825822  0.791037  0.856028  0.808429  \n",
       "225  0.834726  0.794541  0.853999  0.814634  \n",
       "27   0.847091  0.571508  0.852604  0.709299  \n",
       "185  0.828134  0.769784  0.851406  0.798959  \n",
       "95   0.846542  0.748583  0.850466  0.797563  \n",
       "154  0.848089  0.580846  0.849682  0.714468  \n",
       "181  0.791402  0.737531  0.849035  0.764467  \n",
       "330  0.782790  0.818324  0.844948  0.800557  \n",
       "4    0.819013  0.704753  0.843608  0.761883  \n",
       "40   0.818093  0.797458  0.843114  0.807776  \n",
       "291  0.841427  0.532868  0.843059  0.687148  \n",
       "54   0.783661  0.819455  0.842717  0.801558  \n",
       "282  0.837774  0.723748  0.842181  0.780761  \n",
       "182  0.814008  0.777015  0.841949  0.795511  \n",
       "24   0.831853  0.417357  0.841902  0.624605  \n",
       "52   0.835519  0.675537  0.841661  0.755528  \n",
       "298  0.841446  0.718761  0.841210  0.780104  \n",
       "299  0.784110  0.737749  0.841023  0.760929  \n",
       "148  0.822350  0.690653  0.840404  0.756501  \n",
       "251  0.831308  0.719904  0.840167  0.775606  \n",
       "173  0.822192  0.782129  0.839214  0.802160  \n",
       "258  0.812810  0.695274  0.838467  0.754042  \n",
       "183  0.810586  0.735835  0.838315  0.773210  \n",
       "215  0.837300  0.616817  0.835052  0.727059  \n",
       "2    0.812907  0.809927  0.833760  0.811417  \n",
       "284  0.828835  0.630921  0.833420  0.729878  \n",
       "170  0.846686  0.616679  0.833393  0.731682  \n",
       "214  0.829199  0.630945  0.832113  0.730072  \n",
       "72   0.811389  0.765886  0.831524  0.788637  \n",
       "117  0.818496  0.735707  0.831346  0.777101  \n",
       "31   0.815610  0.671300  0.831096  0.743455  \n",
       "65   0.814343  0.745472  0.830079  0.779907  \n",
       "137  0.830288  0.668462  0.829817  0.749375  \n",
       "216  0.834297  0.688205  0.828698  0.761251  \n",
       "5    0.803800  0.748893  0.828165  0.776346  \n",
       "164  0.827867  0.687471  0.827994  0.757669  \n",
       "115  0.810417  0.715471  0.827419  0.762944  \n",
       "135  0.796923  0.723325  0.827103  0.760124  \n",
       "283  0.837993  0.594328  0.826478  0.716161  \n",
       "108  0.812850  0.694287  0.826249  0.753568  \n",
       "328  0.808109  0.742997  0.824743  0.775553  \n",
       "255  0.799457  0.769101  0.823965  0.784279  \n",
       "175  0.821442  0.682869  0.823242  0.752155  \n",
       "42   0.797805  0.757562  0.822025  0.777683  \n",
       "286  0.794918  0.733736  0.820639  0.764327  \n",
       "274  0.810546  0.683144  0.820332  0.746845  \n",
       "13   0.815323  0.729619  0.820224  0.772471  \n",
       "78   0.808198  0.689369  0.819856  0.748783  \n",
       "224  0.796840  0.700803  0.819484  0.748822  \n",
       "140  0.774824  0.697354  0.819226  0.736089  \n",
       "129  0.808235  0.604217  0.819165  0.706226  \n",
       "73   0.785668  0.793849  0.818970  0.789758  \n",
       "30   0.799784  0.651070  0.818109  0.725427  \n",
       "55   0.765958  0.818137  0.817898  0.792047  \n",
       "325  0.829182  0.612303  0.817749  0.720743  \n",
       "334  0.786635  0.719223  0.816748  0.752929  \n",
       "93   0.814584  0.634550  0.816544  0.724567  \n",
       "33   0.781222  0.743856  0.815475  0.762539  \n",
       "273  0.805540  0.660810  0.814707  0.733175  \n",
       "210  0.800810  0.722890  0.814389  0.761850  \n",
       "313  0.803267  0.642116  0.813567  0.722692  \n",
       "264  0.803638  0.720243  0.813418  0.761941  \n",
       "288  0.799814  0.713105  0.811904  0.756460  \n",
       "250  0.823480  0.670745  0.811510  0.747113  \n",
       "227  0.789718  0.750202  0.811355  0.769960  \n",
       "226  0.810331  0.673109  0.810251  0.741720  \n",
       "144  0.798586  0.687061  0.809863  0.742824  \n",
       "120  0.796993  0.694665  0.809393  0.745829  \n",
       "9    0.805585  0.702734  0.809328  0.754159  \n",
       "106  0.798575  0.754467  0.809055  0.776521  \n",
       "309  0.771506  0.718812  0.808981  0.745159  \n",
       "213  0.804909  0.682869  0.808450  0.743889  \n",
       "104  0.749709  0.714394  0.808349  0.732052  \n",
       "10   0.789809  0.761703  0.808042  0.775756  \n",
       "308  0.777191  0.716652  0.807397  0.746921  \n",
       "190  0.792451  0.753670  0.806658  0.773060  \n",
       "233  0.809374  0.584146  0.805850  0.696760  \n",
       "123  0.818898  0.608742  0.805113  0.713820  \n",
       "222  0.818898  0.608742  0.805113  0.713820  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['ak'],ascending=False)[['title','a','k','ak','mean_ak']].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Explainable Machine Learning for Sequences of Demographic Statuses\n",
       "keys                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              XAI\\nDemogrpahic Sequences\\nInterpretable Machine Learning\\nGradient Boosting\\nSHAP\n",
       "abstract    In this paper, we present a case study on demographic sequence analysis through modern machine learning techniques. The studied data contains demographic and socioeconomic events of six Russian generations born in the period 1930-1986, where the events are presented as sequences of statuses. The involved demographers are interested in both applications of advanced machine learning (ML) techniques and interpretable patterns for their needs. Even though the direct application of interpretable machine learning techniques to sequences of statuses is hardly possible at the moment (except pattern mining), we show how Shapley value-based explanations (SHAP library) can be obtained for such sequential data with one of the most powerful ML approaches, namely Gradient Boosting over Decision Trees. Thus, it helps to understand the critical and influencing events for a particular individual life-course sequence and explain predictions.\n",
       "a                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0.835597\n",
       "k                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0.729972\n",
       "ak                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           0.852836\n",
       "Name: 32, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data[8]\n",
    "data2 = data[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_kw = kwords.extract_keywords(data1[2])\n",
    "data1_kw = [words for words,val in data1_kw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_kw = kwords.extract_keywords(data2[2])\n",
    "data2_kw = [words for words,val in data2_kw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['communicate online',\n",
       " 'Danmaku',\n",
       " 'sentiment',\n",
       " 'Network TBAN',\n",
       " 'danmaku sentiment analysis',\n",
       " 'sentiment analysis',\n",
       " 'time',\n",
       " 'improved danmaku sentiment',\n",
       " 'time features',\n",
       " 'video content',\n",
       " 'WiththedevelopmentofInternet,danmakuoffersanewway for users',\n",
       " 'requires external informa',\n",
       " 'users to communicate',\n",
       " 'danmaku sentiment',\n",
       " 'carries limited information',\n",
       " 'features',\n",
       " 'WiththedevelopmentofInternet,danmakuoffersanewway',\n",
       " 'online',\n",
       " 'sentiment analysis method',\n",
       " 'communicate']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Social media',\n",
       " 'social media posts',\n",
       " 'interest areas',\n",
       " 'accessible and effective',\n",
       " 'individuals to offer',\n",
       " 'offer thoughts',\n",
       " 'range of interest',\n",
       " 'sentiment analysis',\n",
       " 'social media platforms',\n",
       " 'sentiment analysis methods',\n",
       " 'sentiment',\n",
       " 'Natural Language Processing',\n",
       " 'Social',\n",
       " 'media',\n",
       " 'analysis',\n",
       " 'Naive Bayes Classifiers',\n",
       " 'large volume',\n",
       " 'effective platform',\n",
       " 'wide range',\n",
       " 'Word Sense Disambiguation']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_kw_v = get_vectors(data1_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_kw_v = get_vectors(data2_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_vec1 = np.zeros([300])\n",
    "for vec in data1_kw_v:\n",
    "    if vec is not None:\n",
    "        sum_vec1 = sum_vec1 + vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_vec2 = np.zeros([300])\n",
    "for vec in data2_kw_v:\n",
    "    if vec is not None:\n",
    "        sum_vec2 = sum_vec2 + vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8559171651111073"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(sum_vec1,sum_vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_l_kw = []\n",
    "for word in data1[1].split('\\n'):\n",
    "    data1_l_kw.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_l_kw = []\n",
    "for word in data2[1].split('\\n'):\n",
    "    data2_l_kw.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentiment analysis', 'danmaku', 'RNN', 'attention']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1_l_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_l_kw_v = get_vectors(data1_l_kw)\n",
    "data2_l_kw_v = get_vectors(data2_l_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_vec1_l = np.zeros([300])\n",
    "for vec in data1_l_kw_v:\n",
    "    if vec is not None:\n",
    "        sum_vec1_l = sum_vec1_l + vec\n",
    "\n",
    "sum_vec2_l = np.zeros([300])\n",
    "for vec in data2_l_kw_v:\n",
    "    if vec is not None:\n",
    "        sum_vec2_l = sum_vec2_l + vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8763649527072961"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(sum_vec1_l+sum_vec1,sum_vec2_l+sum_vec2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f49c6d1816924442c7bb0c650025e1a2b07cf729d403d26c0c18695154c0d85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
